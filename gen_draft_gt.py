#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆè‰ç¨¿æ ‡æ³¨æ–‡ä»¶ (Generate Draft Ground Truth)
åˆ©ç”¨è®­ç»ƒå¥½çš„ YOLOv11 æ¨¡å‹å¯¹è§†é¢‘è¿›è¡Œæ¨ç†å’Œè¿½è¸ªï¼Œè¾“å‡º MOT Challenge æ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
    python gen_draft_gt.py --video path/to/video.webm
    python gen_draft_gt.py --video H:/GSEè®ºæ–‡èµ„æ–™/å®éªŒ/video_data/video.webm
"""

import cv2
import sys
import argparse
import os
from pathlib import Path
from tqdm import tqdm

from ultralytics import YOLO
import config


class DraftGTGenerator:
    """
    è‰ç¨¿æ ‡æ³¨ç”Ÿæˆå™¨
    åŸºäº YOLOv11 + ByteTrack ç”Ÿæˆ MOT Challenge æ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    """
    
    # MOT Challenge æ ‡æ³¨æ ¼å¼
    MOT_FORMAT = "{frame_idx},{track_id},{x1:.2f},{y1:.2f},{w:.2f},{h:.2f},{conf:.2f},{class_id},{dummy1},{dummy2}\n"
    
    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ config.MODEL_PATH
        """
        self.model_path = model_path or config.MODEL_PATH
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {self.model_path}")
        self.model = YOLO(self.model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ç±»åˆ«æ˜ å°„
        self.class_names = self.model.names
        print(f"ğŸ“Š æ£€æµ‹ç±»åˆ«: {list(self.class_names.values())}")
    
    def process_video(self, video_path, output_path=None, conf_threshold=0.1):
        """
        å¤„ç†è§†é¢‘å¹¶ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºæ ‡æ³¨æ–‡ä»¶è·¯å¾„ (é»˜è®¤ä½¿ç”¨è§†é¢‘åŒåçš„ _gt.txt)
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤ 0.1 ä»¥å‡å°‘æ¼æ£€)
        
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # éªŒè¯è§†é¢‘æ–‡ä»¶
        video_file = Path(video_path)
        if not video_file.exists():
            print(f"âŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = str(video_file.parent / f"{video_file.stem}_gt.txt")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ¬ å¤„ç†è§†é¢‘: {video_file.name}")
        print(f"ğŸ“ è¾“å…¥è·¯å¾„: {video_path}")
        print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")
        
        # æ‰“å¼€è§†é¢‘è·å–å¸§æ•°å’Œè§†é¢‘å±æ€§
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"âŒ é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        cap.release()
        
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps, {total_frames} å¸§")
        
        # è¿è¡Œæ¨ç†å’Œè¿½è¸ª
        print(f"\nğŸ” å¼€å§‹æ¨ç†å’Œè¿½è¸ª (conf={conf_threshold})...")
        
        tracked_count = 0
        frame_count = 0
        
        with open(output_path, 'w') as f:
            # ä½¿ç”¨ model.track() è¿›è¡Œæ¨ç†å’Œè¿½è¸ª
            # persist=True: ä¿æŒè¿½è¸ª ID
            # tracker="bytetrack.yaml": ä½¿ç”¨ ByteTrack
            # conf: ç½®ä¿¡åº¦é˜ˆå€¼ (é™ä½ä»¥å‡å°‘æ¼æ£€)
            results = self.model.track(
                source=str(video_path),
                tracker="bytetrack.yaml",
                persist=True,
                conf=conf_threshold,
                stream=True,
                verbose=False
            )
            
            # ä½¿ç”¨è¿›åº¦æ¡å¤„ç†æ¯ä¸€å¸§
            for frame_idx, r in enumerate(tqdm(results, total=total_frames, desc="å¤„ç†å¸§")):
                frame_count += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœå’Œè¿½è¸ª ID
                if r.boxes is not None and r.boxes.id is not None:
                    # æå–æ£€æµ‹ä¿¡æ¯
                    boxes = r.boxes.xywh.cpu().numpy()  # ä¸­å¿ƒåæ ‡ (xc, yc, w, h)
                    track_ids = r.boxes.id.int().cpu().numpy()
                    confidences = r.boxes.conf.cpu().numpy()
                    class_ids = r.boxes.cls.int().cpu().numpy()
                    
                    # é€ä¸ªç›®æ ‡å†™å…¥æ ‡æ³¨
                    for box, track_id, conf, class_id in zip(boxes, track_ids, confidences, class_ids):
                        # æå–åæ ‡å’Œå°ºå¯¸
                        x_center, y_center, w, h = box
                        
                        # è½¬æ¢ä¸ºå·¦ä¸Šè§’åæ ‡ (MOT æ ‡å‡†)
                        x1 = x_center - w / 2
                        y1 = y_center - h / 2
                        
                        # å†™å…¥ MOT Challenge æ ¼å¼
                        # frame_idx ä» 1 å¼€å§‹è®¡æ•° (MOT æ ‡å‡†)
                        line = self.MOT_FORMAT.format(
                            frame_idx=frame_idx + 1,      # å¸§å· (ä» 1 å¼€å§‹)
                            track_id=int(track_id),        # è¿½è¸ª ID
                            x1=x1,                         # å·¦ä¸Šè§’ x
                            y1=y1,                         # å·¦ä¸Šè§’ y
                            w=w,                           # å®½åº¦
                            h=h,                           # é«˜åº¦
                            conf=conf,                     # ç½®ä¿¡åº¦
                            class_id=int(class_id),        # ç±»åˆ« ID
                            dummy1=-1,                     # MOT æ ‡å‡†å ä½ç¬¦
                            dummy2=-1                      # MOT æ ‡å‡†å ä½ç¬¦
                        )
                        f.write(line)
                        tracked_count += 1
        
        # å®Œæˆæç¤º
        print(f"\nâœ… é¢„æ ‡æ³¨å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - å¤„ç†å¸§æ•°: {frame_count}")
        print(f"   - æ£€æµ‹ç›®æ ‡æ•°: {tracked_count}")
        print(f"   - è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"\nğŸ’¡ æç¤º: è¯·ä½¿ç”¨æ ‡æ³¨å·¥å…· (å¦‚ DarkLabel) æ‰“å¼€æ­¤æ–‡ä»¶è¿›è¡Œäººå·¥ä¿®æ­£")
        
        return output_path


def main():
    """
    ä¸»å‡½æ•° - å‘½ä»¤è¡Œå…¥å£
    """
    parser = argparse.ArgumentParser(
        description="ç”Ÿæˆè‰ç¨¿æ ‡æ³¨æ–‡ä»¶ (Generate Draft Ground Truth)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æŒ‡å®šè§†é¢‘æ–‡ä»¶
  python gen_draft_gt.py --video video.webm
  
  # å®Œæ•´è·¯å¾„
  python gen_draft_gt.py --video H:/GSEè®ºæ–‡èµ„æ–™/å®éªŒ/video_data/video.webm
  
  # è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
  python gen_draft_gt.py --video video.webm --output custom_gt.txt
  
  # è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
  python gen_draft_gt.py --video video.webm --conf 0.2
        """
    )
    
    parser.add_argument('--video', '-v', type=str, required=True,
                        help='è¾“å…¥è§†é¢‘è·¯å¾„ (å¿…éœ€)')
    parser.add_argument('--output', '-o', type=str, default=None,
                        help='è¾“å‡ºæ ‡æ³¨æ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨è§†é¢‘åŒå)')
    parser.add_argument('--conf', type=float, default=0.1,
                        help='ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤ 0.1ï¼ŒèŒƒå›´ 0.0-1.0)')
    parser.add_argument('--model', '-m', type=str, default=None,
                        help='æ¨¡å‹è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ config.MODEL_PATH)')
    
    args = parser.parse_args()
    
    # éªŒè¯ç½®ä¿¡åº¦é˜ˆå€¼
    if not 0.0 <= args.conf <= 1.0:
        print(f"âŒ é”™è¯¯: ç½®ä¿¡åº¦é˜ˆå€¼å¿…é¡»åœ¨ 0.0-1.0 ä¹‹é—´ï¼Œå¾—åˆ°: {args.conf}")
        return 1
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = DraftGTGenerator(model_path=args.model)
    
    # å¤„ç†è§†é¢‘
    output_file = generator.process_video(
        video_path=args.video,
        output_path=args.output,
        conf_threshold=args.conf
    )
    
    if output_file is None:
        return 1
    
    print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜: {Path(output_file).absolute()}")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())